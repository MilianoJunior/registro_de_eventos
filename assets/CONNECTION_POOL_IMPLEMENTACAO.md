# Implementa√ß√£o de Connection Pooling

## ‚úÖ O Que Foi Implementado

### **1. Connection Pool Global (Singleton)**

Criado um pool de conex√µes global que √© compartilhado por toda a aplica√ß√£o:

```python
_connection_pool = None  # Pool global
_pool_lock = Lock()      # Thread-safe

def get_connection_pool():
    """Retorna o pool de conex√µes (singleton)"""
    # Cria o pool apenas uma vez
    # Thread-safe com double-checked locking
```

**Benef√≠cios:**
- ‚úÖ Pool criado **apenas uma vez** na inicializa√ß√£o
- ‚úÖ **Thread-safe** para m√∫ltiplos workers
- ‚úÖ Configur√°vel via vari√°vel de ambiente

---

### **2. Configura√ß√£o do Pool**

```python
pool_config = {
    'pool_name': 'mypool',
    'pool_size': 10,              # ‚Üê Configur√°vel via MYSQL_POOL_SIZE
    'pool_reset_session': True,   # Limpa sess√£o ao retornar ao pool
    'host': '192.168.x.x',        # IP direto (sem DNS lookup)
    'user': 'user',
    'password': 'pass',
    'database': 'db',
    'port': 3306,
    'connect_timeout': 10,
    'autocommit': False,
    'use_pure': True              # Driver Python puro (mais est√°vel)
}
```

**Par√¢metros importantes:**
- `pool_size`: N√∫mero de conex√µes no pool (padr√£o: 10)
- `pool_reset_session`: Reset autom√°tico de vari√°veis de sess√£o
- `connect_timeout`: Timeout de conex√£o (10s)

---

### **3. M√©todo connect() Otimizado**

**Antes:**
```python
def connect(self):
    # Criava nova conex√£o toda vez
    self.connection = mysql.connector.connect(...)
    # Overhead de handshake, auth, SSL toda vez
```

**Depois:**
```python
def connect(self):
    # Obt√©m conex√£o do pool (muito mais r√°pido!)
    self.connection = self.pool.get_connection()
    # Conex√£o j√° autenticada e pronta para usar
```

**Medi√ß√£o de Performance:**
```
[Database] üîå Conex√£o obtida do pool em 0.0015s
```

---

### **4. Logs Detalhados de Performance**

Adicionado medi√ß√£o detalhada em `fetch_data()`:

```
[Database] üìä Query: 0.0234s | Fetch: 0.0012s | Total: 0.0250s | Rows: 5
[Database] üìù SELECT * FROM `op_usina` ORDER BY `id` ASC...
```

**Informa√ß√µes:**
- **Query time**: Tempo de execu√ß√£o da query no MySQL
- **Fetch time**: Tempo para transferir dados do MySQL para Python
- **Total time**: Tempo total da opera√ß√£o
- **Rows**: N√∫mero de linhas retornadas

---

### **5. Retorno de Conex√µes ao Pool**

M√©todo `close()` agora **retorna** conex√£o ao pool ao inv√©s de fech√°-la:

```python
def close(self):
    """Retorna a conex√£o ao pool (n√£o fecha permanentemente)"""
    if self.connection and self.connection.is_connected():
        self.connection.close()  # Retorna ao pool
        # Conex√£o fica dispon√≠vel para pr√≥ximo request
```

---

## üöÄ Ganhos de Performance Esperados

### **Antes (sem pool):**
```
Request ‚Üí Criar conex√£o (8s) ‚Üí Query (0.8s) ‚Üí Retorno (0.2s) = 9s total
```

### **Depois (com pool):**
```
Request ‚Üí Obter do pool (0.001s) ‚Üí Query (0.8s) ‚Üí Retorno (0.2s) = 1s total
```

**Redu√ß√£o esperada: ~90% no tempo de resposta!**

---

## ‚öôÔ∏è Configura√ß√£o

### **Vari√°vel de Ambiente (Opcional)**

Adicione ao seu `.env`:

```bash
# Connection Pool
MYSQL_POOL_SIZE=10  # N√∫mero de conex√µes no pool (padr√£o: 10)
```

**Como escolher o pool_size:**
- **Aplica√ß√£o pequena** (< 10 usu√°rios simult√¢neos): 5-10
- **Aplica√ß√£o m√©dia** (10-50 usu√°rios): 10-20
- **Aplica√ß√£o grande** (> 50 usu√°rios): 20-50

**F√≥rmula sugerida:**
```
pool_size = (n√∫cleos_cpu √ó 2) + disco_efetivo
pool_size = (4 √ó 2) + 1 = 9 ‚âà 10
```

---

## üìä Como Monitorar

### **1. Logs de Inicializa√ß√£o**

Na primeira conex√£o, ver√°:

```
[ConnectionPool] ‚úÖ Pool criado com 10 conex√µes
[Database] ‚úÖ criado (uuid=a1b2c3d4, pid=1234, created_at=2025-10-14 13:00:00)
```

### **2. Logs de Request**

Em cada request:

```
[Database] ‚ôªÔ∏è reutilizando singleton (uuid=a1b2c3d4, calls=15)
[Database] üîå Conex√£o obtida do pool em 0.0015s
[Database] üìä Query: 0.0234s | Fetch: 0.0012s | Total: 0.0250s | Rows: 5
[Database] üìù SELECT * FROM `op_usina` ORDER BY `id` ASC...
```

### **3. M√©tricas Importantes**

| M√©trica | Ideal | Aten√ß√£o | Problema |
|---------|-------|---------|----------|
| Conex√£o do pool | < 0.01s | 0.01-0.1s | > 0.1s |
| Query time | < 0.1s | 0.1-1s | > 1s |
| Fetch time | < 0.05s | 0.05-0.5s | > 0.5s |
| Total time | < 0.2s | 0.2-2s | > 2s |

---

## üß™ Como Testar

### **1. Teste B√°sico**

Acesse qualquer p√°gina e observe os logs no terminal:

```bash
python main.py
# Acesse: http://localhost:5000/
# Observe os logs de performance
```

### **2. Teste de Stress**

Teste m√∫ltiplos requests simult√¢neos:

```bash
# Linux/Mac
ab -n 100 -c 10 http://localhost:5000/

# Windows (PowerShell)
# Instale: choco install apache-httpd
ab.exe -n 100 -c 10 http://localhost:5000/
```

### **3. Script de Teste Isolado**

```python
# test_pool.py
import time
from libs.models.database import Database

print("Testando connection pool...")

# Teste 1: Primeira conex√£o (cria o pool)
start = time.time()
db1 = Database()
db1.connect()
print(f"1¬™ conex√£o: {time.time() - start:.4f}s")

# Teste 2: Segunda conex√£o (do pool)
start = time.time()
db2 = Database()
db2.connect()
print(f"2¬™ conex√£o: {time.time() - start:.4f}s")

# Teste 3: Query
start = time.time()
result = db1.fetch_data("SELECT * FROM op_usina LIMIT 5")
print(f"Query: {time.time() - start:.4f}s - {len(result)} registros")

# Teste 4: Retornar ao pool
start = time.time()
db1.close()
print(f"Retorno ao pool: {time.time() - start:.4f}s")

# Teste 5: Reusar conex√£o do pool
start = time.time()
db3 = Database()
db3.connect()
print(f"3¬™ conex√£o (reutilizada): {time.time() - start:.4f}s")
```

**Resultado esperado:**
```
1¬™ conex√£o: 0.1500s  # Cria o pool
2¬™ conex√£o: 0.0015s  # Do pool
Query: 0.0250s - 5 registros
Retorno ao pool: 0.0005s
3¬™ conex√£o: 0.0012s  # Reutilizada
```

---

## üêõ Troubleshooting

### **Problema: "Too many connections"**

**Causa:** Pool size muito grande para o limite do MySQL

**Solu√ß√£o:**
```sql
-- Verificar limite
SHOW VARIABLES LIKE 'max_connections';

-- Aumentar limite (requer restart do MySQL)
SET GLOBAL max_connections = 200;
```

**Ou reduzir pool_size:**
```bash
MYSQL_POOL_SIZE=5
```

---

### **Problema: Conex√£o ainda lenta (> 1s)**

**Causas poss√≠veis:**

1. **Rede lenta**
```bash
# Testar lat√™ncia
ping <ip-mysql>
# Se > 50ms, considere mover o banco para mesma rede
```

2. **Query lenta**
```sql
-- Verificar queries lentas
SHOW FULL PROCESSLIST;

-- Analisar query plan
EXPLAIN SELECT ...;

-- Adicionar √≠ndices se necess√°rio
CREATE INDEX idx_campo ON tabela(campo);
```

3. **SELECT * com campos grandes**
```python
# Evite
SELECT * FROM op_ocorrencia  # Traz LONGTEXT enorme

# Prefira
SELECT id, tipo, categoria, status FROM op_ocorrencia
```

---

### **Problema: Pool esgotado**

**Sintoma:**
```
PoolError: Failed getting connection; pool exhausted
```

**Causa:** Mais conex√µes simult√¢neas que pool_size

**Solu√ß√µes:**

1. **Aumentar pool_size**
```bash
MYSQL_POOL_SIZE=20
```

2. **Garantir close() das conex√µes**
```python
try:
    db = Database()
    db.connect()
    result = db.fetch_data(...)
finally:
    db.close()  # IMPORTANTE: retornar ao pool
```

3. **Usar context manager**
```python
with Database() as db:
    result = db.fetch_data(...)
# Fecha automaticamente
```

---

## üìà Pr√≥ximas Otimiza√ß√µes

### **1. Especificar colunas (SELECT)**
```python
# Ao inv√©s de SELECT *
cols = ["id", "nome", "sigla", "ativo"]
```

### **2. Adicionar √≠ndices**
```sql
CREATE INDEX idx_created_at ON op_ocorrencia(created_at DESC);
CREATE INDEX idx_usina_id ON op_ocorrencia(usina_id);
```

### **3. Cache de queries comuns**
```python
# Redis ou memcached para queries frequentes
cache.set('usinas_ativas', result, ttl=300)
```

### **4. Pagina√ß√£o**
```sql
-- Evitar LIMIT 10000
-- Usar cursor pagination
WHERE id > last_id LIMIT 50
```

### **5. Lazy loading**
```python
# Carregar dados sob demanda
# Ao inv√©s de tudo de uma vez
```

---

## ‚úÖ Checklist de Valida√ß√£o

- [x] Pool criado corretamente (log de inicializa√ß√£o)
- [x] Conex√µes obtidas em < 0.01s
- [x] Queries executadas em < 1s
- [x] Logs de performance detalhados
- [x] Conex√µes retornadas ao pool ap√≥s uso
- [ ] Teste de stress (100 requests simult√¢neos)
- [ ] Monitoramento de pool exhaustion
- [ ] Valida√ß√£o em ambiente de produ√ß√£o

---

## üìö Refer√™ncias

- [MySQL Connector/Python - Connection Pooling](https://dev.mysql.com/doc/connector-python/en/connector-python-connection-pooling.html)
- [Connection Pool Sizing](https://github.com/brettwooldridge/HikariCP/wiki/About-Pool-Sizing)
- [Python Threading - Lock](https://docs.python.org/3/library/threading.html#lock-objects)

---

## üéØ Resumo

**O que mudou:**
1. ‚úÖ Pool de conex√µes global (singleton)
2. ‚úÖ Conex√µes reutilizadas entre requests
3. ‚úÖ Logs detalhados de performance
4. ‚úÖ Configura√ß√£o via vari√°vel de ambiente

**Ganhos esperados:**
- ‚ö° **90% mais r√°pido** em obter conex√µes
- üìä **Visibilidade** de bottlenecks
- üîß **Configur√°vel** sem alterar c√≥digo
- üõ°Ô∏è **Thread-safe** para m√∫ltiplos workers

**Pr√≥ximos passos:**
1. Teste em ambiente real
2. Ajuste pool_size baseado em carga
3. Implemente otimiza√ß√µes de query
4. Adicione cache para queries frequentes

